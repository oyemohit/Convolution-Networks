{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Implementation  \n",
    "  \n",
    "    \n",
    "      \n",
    "      \n",
    "  \n",
    "This Model implements the model described in the [**AlexNet paper.**](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)    \n",
    "  \n",
    "  AlexNet trained a large, deep convolutional neural network to classify the **1.2 million high-resolution images** in the ImageNet LSVRC-2010 contest into the 1000 different classes.  \n",
    "  It has **60 million parameters and 650,000 neurons**, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax\n",
    "  \n",
    "The model is implemented in **Keras with tensorflow backend.**  \n",
    "  \n",
    "Below Cell imports the required python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "import pydotplus\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import scipy\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Explore the Data\n",
    "\n",
    "For this Model, we are using the database of various **fashion products** sorted by two labels **product type** and **brands**.  \n",
    "This dataset was taken from the [kaggle.](https://www.kaggle.com/olgabelitskaya/style-color-images)  \n",
    "\n",
    "The dataset consists of :\n",
    "+ **894 color images (150x150x3)**- 715 Training Images and 179 Test Images\n",
    "+ **7 brands and 10 products**\n",
    "\n",
    "and the file with labels is style.csv. Photo files are in the .png format and the labels are integers and values.  \n",
    "  \n",
    "Since there are two labels, we can train our model to classify any one of them...here we trained it to detect **Product Type**\n",
    "\n",
    "\n",
    "Run the following cell to load the dataset labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand Names: {'Gucci', 'Christian Louboutin', 'Versace', 'Yves Saint Laurent', 'Christian Dior', 'Dolce & Gabbana', 'Chanel'}\n",
      "\n",
      "Product Types: {'handbag', 'necklace', 'ring', 'nail polish', 'earrings', 'bracelet', 'lipstick', 'boots', 'shoes', 'watches'}\n"
     ]
    }
   ],
   "source": [
    "#Objective:Explores the dataset\n",
    "#inputs:path of data file\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:pandas library is used to read and explore data\n",
    "\n",
    "data = pd.read_csv(\"data/style.csv\")\n",
    "print(\"Brand Names:\",set(data['brand_name']))\n",
    "print(\"\\nProduct Types:\",set(data['product_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell defines the functions for converting the image data into tensors for input to Model's first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective:Function for processing an image and converting it into tensor\n",
    "#inputs:path of img_file\n",
    "#Outputs:image tensor\n",
    "#invoked by:data_to_tensor()\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "def image_to_tensor(img_path):\n",
    "    img = keras_image.load_img(\"data/style/\" + img_path, target_size=(150, 150))\n",
    "    x = keras_image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "#Objective: Function for creating the data tensor\n",
    "#inputs:path of img_file\n",
    "#Outputs:list of tensors\n",
    "#invoked by:Main\n",
    "#invokes:image_to_tensor()\n",
    "#approach:N/A\n",
    "def data_to_tensor(img_paths):\n",
    "    list_of_tensors = [image_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below cell to convert data labels to matrices and load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 894/894 [00:01<00:00, 498.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#Objective: Creates Tensors for labels as images\n",
    "#inputs:N/A\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:data_to_tensor()\n",
    "#approach:N/A\n",
    "\n",
    "brands = data['brand_label'].as_matrix()\n",
    "products = data['product_label'].as_matrix()\n",
    "images = data_to_tensor(data['file']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Dimensions of all Vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (894, 150, 150, 3)\n",
      "Brand shape (894,)\n",
      "Product shape (894,)\n"
     ]
    }
   ],
   "source": [
    "#Objective: Prints shapes of labels and images\n",
    "#inputs:N/A\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "print ('Image shape:', images.shape)\n",
    "print ('Brand shape', brands.shape)\n",
    "print ('Product shape', products.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell packs the images and labels into h5 format for efficient processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (894, 150, 150, 3)\n",
      "Brand shape (894,)\n",
      "Product shape (894,)\n"
     ]
    }
   ],
   "source": [
    "#Objective: Create the tensor file\n",
    "#inputs: path to save h5 file and data tensors\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "\n",
    "with h5py.File('data/StyleColorImages.h5', 'w') as f:\n",
    "    f.create_dataset('images', data = images)\n",
    "    f.create_dataset('brands', data = brands)\n",
    "    f.create_dataset('products', data = products)\n",
    "    f.close()\n",
    "# Read the h5 file\n",
    "f = h5py.File('data/StyleColorImages.h5', 'r')\n",
    "\n",
    "# List all groups\n",
    "keys = list(f.keys())\n",
    "\n",
    "# Create tensors and targets\n",
    "brands = np.array(f[keys[0]])\n",
    "images = np.array(f[keys[1]])\n",
    "products = np.array(f[keys[2]])\n",
    "\n",
    "print ('Image shape:', images.shape)\n",
    "print ('Brand shape', brands.shape)\n",
    "print ('Product shape', products.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(894, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Objective: Normalize & one hot encode tensors\n",
    "#inputs: label tensors\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "\n",
    "images = images.astype('float32')/255\n",
    "# One-hot encode the products\n",
    "cat_products = to_categorical(products, 10)\n",
    "cat_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below cell to look at a particular image from dataset...(You can change value of i for corresponding image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product:  shoes\n",
      "Brand:  Christian Dior\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAADFCAYAAADzGqY5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d954d27898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Objective: Read and display an image tensor using Matplotlib\n",
    "#inputs: image & label tensors\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "\n",
    "i=526\n",
    "print('Product: ', data['product_name'][i])\n",
    "print('Brand: ', data['brand_name'][i])\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(images[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the image vectors and create one hot encodings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data, Here:\n",
    "+ Training size is 80% of dataset : **715 images**\n",
    "+ Testing size is 20% of dataset : **179 images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensor's shape: (715, 150, 150, 3)\n",
      "Training target's shape (715, 10)\n",
      "Testing tensor's shape: (179, 150, 150, 3)\n",
      "Testing target's shape (179, 10)\n"
     ]
    }
   ],
   "source": [
    "#Objective:Split the data into train & test\n",
    "#inputs: image & label tensors\n",
    "#Outputs:x_train,y_train,x_test,y_test\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, cat_products, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 1)\n",
    "# Print the shape\n",
    "print (\"Training tensor's shape:\", x_train.shape)\n",
    "print (\"Training target's shape\", y_train.shape)\n",
    "print (\"Testing tensor's shape:\", x_test.shape)\n",
    "print (\"Testing target's shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Description:  \n",
    "\n",
    "Below Model uses **5 Convolution layers**:\n",
    "+ First Conv layer use **96 Filters of size 11 x 11, strides: 4, No Padding and Relu activation**\n",
    "+ First Conv layer use **256 Filters of size 5 x 5, Same Padding and Relu activation**\n",
    "+ First Conv layer use **384 Filters of size 3 x 3, Same Padding and Relu activation**\n",
    "+ First Conv layer use **384 Filters of size 3 x 3, Same Padding and Relu activation**\n",
    "+ First Conv layer use **256 Filters of size 3 x 3, Same Padding and Relu activation**\n",
    "  \n",
    "There are **3 MaxPool layers**,in which:\n",
    "+ Filter size : **3 x 3**\n",
    "+ Strides : **2**\n",
    "\n",
    "And **3 fully connected layers**:\n",
    "+ First fully connected layer has **1024 hidden units** and uses **Relu activation**\n",
    "+ Second fully connected layer has **1024 hidden units** and uses **Relu activation**\n",
    "+ Third fully connected layer has **10 hidden units** and uses **Softmax activation**\n",
    "  \n",
    "  \n",
    "After Convolution stages, The images are **flattened** and feeded to fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective:Implements & Compiles the AlexNet architecture on given parameters\n",
    "#inputs:Shape of input image & No. of classes and Optimzer & loss function to be used\n",
    "#Outputs:Returns the implemented CNN model\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:Uses Keras library functions to implement CNN model\n",
    "\n",
    "def cp_model():\n",
    "    classifier = Sequential()\n",
    "    #convolutional layer\n",
    "    classifier.add(Conv2D(96, (11, 11), strides=4,input_shape = (150, 150, 3), activation = 'relu'))\n",
    "\n",
    "    classifier.add(MaxPooling2D(pool_size = (3, 3),strides=2))\n",
    "   \n",
    "    classifier.add(Conv2D(256, (5, 5),padding='same',activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (3, 3),strides=2))\n",
    "    classifier.add(Conv2D(384, (3, 3),padding='same',activation = 'relu'))\n",
    "    classifier.add(Conv2D(384, (3, 3),padding='same',activation = 'relu'))\n",
    "    classifier.add(Conv2D(256, (3, 3),padding='same',activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (3, 3),strides=2))\n",
    "    #Flattening\n",
    "    classifier.add(Flatten())\n",
    "    #Full connection\n",
    "    classifier.add(Dense(units = 1024, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1024, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 10, activation = 'softmax'))\n",
    "    # Compiling the CNN\n",
    "    classifier.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_model = cp_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is ready to be trained on the traing set, Here we used:\n",
    "+ No. of iterations: **5**\n",
    "+ Size of mini batches: **16**  \n",
    "\n",
    "Run the following cell to train the model on 5 iterations with a batch size of 16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "715/715 [==============================] - ETA: 2:00 - loss: 2.2935 - acc: 0.250 - ETA: 1:49 - loss: 2.2975 - acc: 0.156 - ETA: 1:43 - loss: 2.2951 - acc: 0.104 - ETA: 1:38 - loss: 2.2920 - acc: 0.156 - ETA: 1:31 - loss: 2.2842 - acc: 0.200 - ETA: 1:26 - loss: 2.2821 - acc: 0.208 - ETA: 1:21 - loss: 2.2812 - acc: 0.205 - ETA: 1:18 - loss: 2.2812 - acc: 0.203 - ETA: 1:15 - loss: 2.2785 - acc: 0.194 - ETA: 1:12 - loss: 2.2697 - acc: 0.206 - ETA: 1:10 - loss: 2.2700 - acc: 0.187 - ETA: 1:07 - loss: 2.2726 - acc: 0.192 - ETA: 1:05 - loss: 2.2747 - acc: 0.192 - ETA: 1:02 - loss: 2.2739 - acc: 0.192 - ETA: 1:00 - loss: 2.2756 - acc: 0.191 - ETA: 58s - loss: 2.2766 - acc: 0.179 - ETA: 56s - loss: 2.2692 - acc: 0.20 - ETA: 53s - loss: 2.2637 - acc: 0.20 - ETA: 51s - loss: 2.2631 - acc: 0.19 - ETA: 49s - loss: 2.2599 - acc: 0.20 - ETA: 47s - loss: 2.2606 - acc: 0.20 - ETA: 45s - loss: 2.2567 - acc: 0.20 - ETA: 43s - loss: 2.2523 - acc: 0.20 - ETA: 40s - loss: 2.2504 - acc: 0.20 - ETA: 38s - loss: 2.2408 - acc: 0.21 - ETA: 36s - loss: 2.2380 - acc: 0.21 - ETA: 34s - loss: 2.2423 - acc: 0.21 - ETA: 33s - loss: 2.2437 - acc: 0.20 - ETA: 31s - loss: 2.2343 - acc: 0.20 - ETA: 29s - loss: 2.2340 - acc: 0.21 - ETA: 27s - loss: 2.2341 - acc: 0.20 - ETA: 25s - loss: 2.2333 - acc: 0.20 - ETA: 23s - loss: 2.2363 - acc: 0.20 - ETA: 21s - loss: 2.2340 - acc: 0.21 - ETA: 19s - loss: 2.2312 - acc: 0.21 - ETA: 17s - loss: 2.2316 - acc: 0.20 - ETA: 15s - loss: 2.2169 - acc: 0.21 - ETA: 13s - loss: 2.2100 - acc: 0.22 - ETA: 11s - loss: 2.2100 - acc: 0.21 - ETA: 9s - loss: 2.2152 - acc: 0.2172 - ETA: 7s - loss: 2.2186 - acc: 0.214 - ETA: 5s - loss: 2.2184 - acc: 0.212 - ETA: 3s - loss: 2.2142 - acc: 0.219 - ETA: 1s - loss: 2.2182 - acc: 0.215 - 91s 127ms/step - loss: 2.2193 - acc: 0.2168\n",
      "Epoch 2/5\n",
      "715/715 [==============================] - ETA: 1:29 - loss: 2.2652 - acc: 0.187 - ETA: 1:24 - loss: 2.2624 - acc: 0.250 - ETA: 1:20 - loss: 2.2225 - acc: 0.250 - ETA: 1:18 - loss: 2.2483 - acc: 0.250 - ETA: 1:16 - loss: 2.2483 - acc: 0.237 - ETA: 1:13 - loss: 2.2535 - acc: 0.239 - ETA: 1:12 - loss: 2.2264 - acc: 0.258 - ETA: 1:09 - loss: 2.2063 - acc: 0.250 - ETA: 1:07 - loss: 2.1825 - acc: 0.263 - ETA: 1:05 - loss: 2.1857 - acc: 0.250 - ETA: 1:04 - loss: 2.1956 - acc: 0.238 - ETA: 1:03 - loss: 2.1800 - acc: 0.265 - ETA: 1:01 - loss: 2.1761 - acc: 0.274 - ETA: 59s - loss: 2.1823 - acc: 0.263 - ETA: 57s - loss: 2.1741 - acc: 0.27 - ETA: 55s - loss: 2.1796 - acc: 0.26 - ETA: 53s - loss: 2.1912 - acc: 0.25 - ETA: 50s - loss: 2.1929 - acc: 0.25 - ETA: 48s - loss: 2.1859 - acc: 0.26 - ETA: 46s - loss: 2.1841 - acc: 0.26 - ETA: 44s - loss: 2.1829 - acc: 0.25 - ETA: 43s - loss: 2.1755 - acc: 0.26 - ETA: 41s - loss: 2.1618 - acc: 0.26 - ETA: 39s - loss: 2.1676 - acc: 0.26 - ETA: 37s - loss: 2.1645 - acc: 0.27 - ETA: 35s - loss: 2.1697 - acc: 0.26 - ETA: 33s - loss: 2.1675 - acc: 0.27 - ETA: 31s - loss: 2.1646 - acc: 0.27 - ETA: 29s - loss: 2.1646 - acc: 0.27 - ETA: 27s - loss: 2.1595 - acc: 0.27 - ETA: 25s - loss: 2.1645 - acc: 0.28 - ETA: 23s - loss: 2.1589 - acc: 0.28 - ETA: 21s - loss: 2.1529 - acc: 0.28 - ETA: 20s - loss: 2.1571 - acc: 0.28 - ETA: 18s - loss: 2.1532 - acc: 0.28 - ETA: 16s - loss: 2.1511 - acc: 0.29 - ETA: 14s - loss: 2.1405 - acc: 0.29 - ETA: 12s - loss: 2.1446 - acc: 0.29 - ETA: 10s - loss: 2.1507 - acc: 0.29 - ETA: 8s - loss: 2.1520 - acc: 0.2875 - ETA: 6s - loss: 2.1550 - acc: 0.285 - ETA: 5s - loss: 2.1558 - acc: 0.282 - ETA: 3s - loss: 2.1581 - acc: 0.280 - ETA: 1s - loss: 2.1562 - acc: 0.284 - 84s 117ms/step - loss: 2.1617 - acc: 0.2797\n",
      "Epoch 3/5\n",
      "715/715 [==============================] - ETA: 1:27 - loss: 2.0868 - acc: 0.375 - ETA: 1:24 - loss: 2.0652 - acc: 0.375 - ETA: 1:20 - loss: 2.0556 - acc: 0.354 - ETA: 1:17 - loss: 2.0662 - acc: 0.328 - ETA: 1:15 - loss: 2.0502 - acc: 0.325 - ETA: 1:13 - loss: 2.0414 - acc: 0.322 - ETA: 1:11 - loss: 2.0562 - acc: 0.312 - ETA: 1:09 - loss: 2.0754 - acc: 0.304 - ETA: 1:07 - loss: 2.0621 - acc: 0.305 - ETA: 1:06 - loss: 2.0768 - acc: 0.300 - ETA: 1:04 - loss: 2.1044 - acc: 0.289 - ETA: 1:02 - loss: 2.1148 - acc: 0.281 - ETA: 1:00 - loss: 2.1213 - acc: 0.274 - ETA: 58s - loss: 2.1318 - acc: 0.267 - ETA: 56s - loss: 2.1218 - acc: 0.28 - ETA: 54s - loss: 2.1393 - acc: 0.28 - ETA: 52s - loss: 2.1377 - acc: 0.28 - ETA: 50s - loss: 2.1259 - acc: 0.28 - ETA: 48s - loss: 2.1283 - acc: 0.27 - ETA: 46s - loss: 2.1297 - acc: 0.27 - ETA: 44s - loss: 2.1298 - acc: 0.27 - ETA: 42s - loss: 2.1300 - acc: 0.27 - ETA: 40s - loss: 2.1288 - acc: 0.27 - ETA: 38s - loss: 2.1214 - acc: 0.27 - ETA: 37s - loss: 2.1387 - acc: 0.27 - ETA: 35s - loss: 2.1405 - acc: 0.26 - ETA: 33s - loss: 2.1352 - acc: 0.26 - ETA: 31s - loss: 2.1365 - acc: 0.26 - ETA: 29s - loss: 2.1377 - acc: 0.26 - ETA: 27s - loss: 2.1308 - acc: 0.27 - ETA: 25s - loss: 2.1426 - acc: 0.26 - ETA: 23s - loss: 2.1462 - acc: 0.26 - ETA: 22s - loss: 2.1469 - acc: 0.26 - ETA: 20s - loss: 2.1482 - acc: 0.26 - ETA: 18s - loss: 2.1512 - acc: 0.26 - ETA: 16s - loss: 2.1481 - acc: 0.26 - ETA: 14s - loss: 2.1526 - acc: 0.26 - ETA: 12s - loss: 2.1578 - acc: 0.26 - ETA: 10s - loss: 2.1546 - acc: 0.26 - ETA: 8s - loss: 2.1524 - acc: 0.2734 - ETA: 6s - loss: 2.1573 - acc: 0.271 - ETA: 5s - loss: 2.1514 - acc: 0.272 - ETA: 3s - loss: 2.1579 - acc: 0.268 - ETA: 1s - loss: 2.1585 - acc: 0.268 - 84s 117ms/step - loss: 2.1564 - acc: 0.2699\n",
      "Epoch 4/5\n",
      "715/715 [==============================] - ETA: 1:19 - loss: 2.1288 - acc: 0.250 - ETA: 1:18 - loss: 1.9955 - acc: 0.343 - ETA: 1:16 - loss: 2.0673 - acc: 0.333 - ETA: 1:14 - loss: 2.1235 - acc: 0.281 - ETA: 1:13 - loss: 2.0819 - acc: 0.300 - ETA: 1:11 - loss: 2.0388 - acc: 0.322 - ETA: 1:09 - loss: 2.0866 - acc: 0.303 - ETA: 1:07 - loss: 2.1135 - acc: 0.281 - ETA: 1:05 - loss: 2.1105 - acc: 0.291 - ETA: 1:03 - loss: 2.1734 - acc: 0.262 - ETA: 1:01 - loss: 2.1881 - acc: 0.250 - ETA: 1:00 - loss: 2.1947 - acc: 0.234 - ETA: 58s - loss: 2.1972 - acc: 0.240 - ETA: 56s - loss: 2.1965 - acc: 0.24 - ETA: 54s - loss: 2.1948 - acc: 0.24 - ETA: 52s - loss: 2.2004 - acc: 0.24 - ETA: 50s - loss: 2.1942 - acc: 0.25 - ETA: 49s - loss: 2.1986 - acc: 0.25 - ETA: 47s - loss: 2.2011 - acc: 0.25 - ETA: 45s - loss: 2.1926 - acc: 0.25 - ETA: 43s - loss: 2.1771 - acc: 0.26 - ETA: 41s - loss: 2.1675 - acc: 0.26 - ETA: 39s - loss: 2.1595 - acc: 0.27 - ETA: 38s - loss: 2.1485 - acc: 0.27 - ETA: 36s - loss: 2.1557 - acc: 0.27 - ETA: 34s - loss: 2.1566 - acc: 0.27 - ETA: 32s - loss: 2.1589 - acc: 0.27 - ETA: 30s - loss: 2.1822 - acc: 0.26 - ETA: 28s - loss: 2.1847 - acc: 0.26 - ETA: 27s - loss: 2.1693 - acc: 0.26 - ETA: 25s - loss: 2.1628 - acc: 0.27 - ETA: 23s - loss: 2.1843 - acc: 0.27 - ETA: 21s - loss: 2.1858 - acc: 0.27 - ETA: 19s - loss: 2.1929 - acc: 0.27 - ETA: 17s - loss: 2.2053 - acc: 0.26 - ETA: 16s - loss: 2.2124 - acc: 0.26 - ETA: 14s - loss: 2.2127 - acc: 0.26 - ETA: 12s - loss: 2.2077 - acc: 0.27 - ETA: 10s - loss: 2.2018 - acc: 0.27 - ETA: 8s - loss: 2.2034 - acc: 0.2734 - ETA: 6s - loss: 2.2029 - acc: 0.271 - ETA: 4s - loss: 2.2092 - acc: 0.264 - ETA: 3s - loss: 2.2153 - acc: 0.263 - ETA: 1s - loss: 2.2142 - acc: 0.264 - 83s 115ms/step - loss: 2.2078 - acc: 0.2685\n",
      "Epoch 5/5\n",
      "715/715 [==============================] - ETA: 1:21 - loss: 4.4605 - acc: 0.125 - ETA: 1:20 - loss: 4.4640 - acc: 0.125 - ETA: 1:21 - loss: 4.9226 - acc: 0.104 - ETA: 1:18 - loss: 6.9659 - acc: 0.125 - ETA: 1:15 - loss: 8.5949 - acc: 0.112 - ETA: 1:14 - loss: 9.6809 - acc: 0.104 - ETA: 1:11 - loss: 10.3126 - acc: 0.10 - ETA: 1:09 - loss: 10.9124 - acc: 0.10 - ETA: 1:07 - loss: 11.4908 - acc: 0.09 - ETA: 1:05 - loss: 11.8528 - acc: 0.08 - ETA: 1:03 - loss: 11.8742 - acc: 0.10 - ETA: 1:01 - loss: 12.1279 - acc: 0.09 - ETA: 59s - loss: 12.0474 - acc: 0.1154 - ETA: 57s - loss: 11.9783 - acc: 0.129 - ETA: 55s - loss: 11.9185 - acc: 0.141 - ETA: 53s - loss: 11.8662 - acc: 0.152 - ETA: 51s - loss: 11.9385 - acc: 0.154 - ETA: 49s - loss: 12.0028 - acc: 0.156 - ETA: 47s - loss: 12.0074 - acc: 0.161 - ETA: 45s - loss: 12.1625 - acc: 0.156 - ETA: 43s - loss: 12.1590 - acc: 0.160 - ETA: 41s - loss: 12.2016 - acc: 0.161 - ETA: 40s - loss: 12.2405 - acc: 0.163 - ETA: 38s - loss: 12.3601 - acc: 0.158 - ETA: 36s - loss: 12.4298 - acc: 0.157 - ETA: 34s - loss: 12.3392 - acc: 0.165 - ETA: 32s - loss: 12.4045 - acc: 0.164 - ETA: 30s - loss: 12.3213 - acc: 0.171 - ETA: 28s - loss: 12.3827 - acc: 0.170 - ETA: 27s - loss: 12.3393 - acc: 0.175 - ETA: 25s - loss: 12.3638 - acc: 0.175 - ETA: 23s - loss: 12.3866 - acc: 0.175 - ETA: 21s - loss: 12.4081 - acc: 0.176 - ETA: 19s - loss: 12.4284 - acc: 0.176 - ETA: 17s - loss: 12.4187 - acc: 0.178 - ETA: 16s - loss: 12.3815 - acc: 0.182 - ETA: 14s - loss: 12.4553 - acc: 0.179 - ETA: 12s - loss: 12.4721 - acc: 0.179 - ETA: 10s - loss: 12.5398 - acc: 0.176 - ETA: 8s - loss: 12.6041 - acc: 0.173 - ETA: 6s - loss: 12.6161 - acc: 0.17 - ETA: 4s - loss: 12.6275 - acc: 0.17 - ETA: 3s - loss: 12.5681 - acc: 0.17 - ETA: 1s - loss: 12.5801 - acc: 0.17 - 83s 115ms/step - loss: 12.5894 - acc: 0.1790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d900028550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Objective:Fits i.e. Trains the above compiled model on given training data\n",
    "#inputs:x_train, y_train, no. of iterations and Batch size\n",
    "#Outputs:loss & accuracy after every iteration\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "cp_model.fit(x_train, y_train,epochs=5, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 7s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "#Objective:Evaluates the above trained model on test data\n",
    "#inputs:x_test, y_test\n",
    "#Outputs:Loss & Accuracy on test data\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "preds = cp_model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 12.2461506721\n",
      "Test Accuracy = 0.240223463854\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a **summary** of the above model.    \n",
    "  \n",
    "  \n",
    "It shows the **dimensions of output** at every layer and the **no. of parameters** at every layer.  \n",
    "  \n",
    "  Total trainable Parameters in the model: **7,167,370**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 35, 35, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 7,167,370\n",
      "Trainable params: 7,167,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Objective:Displays the summary of the model (shape & No. of parameters at every layer)\n",
    "#inputs:N/A\n",
    "#Outputs:N/A\n",
    "#invoked by:N/A\n",
    "#invokes:N/A\n",
    "#approach:N/A\n",
    "\n",
    "cp_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
